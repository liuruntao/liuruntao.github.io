<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Runtao Liu - Homepage</title>
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="style_append.css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
</head>
<body>

    <div class="header">
        <div class="header-left">
            <h1>Runtao Liu</h1>
            <div class="contact-info">
                <div class="contact-links">
                    <a href="mailto:rliuay@connect.ust.hk">Email</a> /
                    <a href="https://scholar.google.com/citations?user=ABC&user=YHTvXF4AAAAJ">Google Scholar</a>
                </div>
            </div>
            <p>
                I am a Ph.D. candidate in <a href="https://hkust.edu.hk/">Hong Kong University of Science and Technology (HKUST)</a>, advised by Prof. <a href="https://cqf.io/">Qifeng Chen</a>. 
                I am also a Visiting Student at the <a href="https://www.ox.ac.uk/">University of Oxford</a> in the Torr Vision Group, working with Prof. <a href="https://www.robots.ox.ac.uk/~phst/">Philip Torr</a>.
                <!-- Previously, I was a Ph.D. student at Johns Hopkins University (2021-2022) advised by Prof. <a href="https://www.cs.jhu.edu/~ayuille/">Alan Yuille</a>.  -->
                I received my Master's degree from Peking University and Bachelor's degree from Beijing University of Posts and Telecommunications.
                I have also spent wonderful time as a research intern at Disney Research Zürich working with <a href="https://studios.disneyresearch.com/people/yang-zhang/">Dr. Yang Zhang</a>, an assistant researcher at Microsoft Research Asia working with <a href="https://www.zirongw.com/">Dr. Zhirong Wu</a> and <a href="https://www.microsoft.com/en-us/research/people/stevelin/">Dr. Steve Lin</a>, and a visiting student at UC Berkeley working with <a href="https://web.eecs.umich.edu/~stellayu/">Prof. Stella Yu</a> and Johns Hopkins University working with <a href="https://www.cs.jhu.edu/~ayuille/">Prof. Alan Yuille</a>.
            </p>
            <p>
                My research interests include Generative AI, Reinforcement Learning, Agents, and Visual Generation/Understanding:
            </p>
            <p>
                Agent/RL for GenAI: <a href="https://arxiv.org/abs/2512.20618">LongVideoAgent</a>, <a href="https://arxiv.org/abs/2412.14167">VideoDPO</a>, <a href="https://arxiv.org/abs/2412.10493">SafetyDPO</a>, <a href="https://arxiv.org/abs/2403.08730">Bootstrapped Preference Optimization</a>
                <br>
                Visual understanding and generation: <a href="https://arxiv.org/abs/1901.00850">Clevr-Ref+</a>, <a href="https://arxiv.org/abs/2111.06394">Appearance Motion Decomposition</a>, <a href="https://arxiv.org/abs/1909.08313">Unsupervised Sketch-to-Photo Synthesis</a>
                <br>
                GenAI Safety & Robustness: <a href="https://arxiv.org/abs/2512.17532">Robust-R1</a>, <a href="https://arxiv.org/abs/2412.10493">SafetyDPO</a>, <a href="https://arxiv.org/abs/2404.08031">LatentGuard</a>
            </p>
        </div>
    </div>

    <div class="section">
        <h2>News</h2>
        <div class="section-content">
            <p style="color: red; font-weight: bold;">
                I am seeking industrial and academic full-time researcher positions in 2026. Please feel free to contact me if you are interested in my research.
            </p>
            <div class="news-item">
                <span class="news-date">Dec. 24, 2025:</span>
                LongVideoAgent is released on <a href="https://arxiv.org/abs/2512.20618">arXiv</a>.
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Research Experience</h2>
        <div class="section-content">
            <div class="experience-item">
                <div class="experience-logo">
                    <img src="images/oxford_logo.png" alt="Oxford Logo">
                </div>
                <div class="experience-details">
                    <strong>University of Oxford</strong>, Visiting Student (June 2023 - Present)
                    <br>Advisor: Prof. Philip Torr
                </div>
            </div>

            <div class="experience-item">
                <div class="experience-logo">
                    <img src="https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20190129095849/dr.png" alt="Disney Research Logo">
                </div>
                <div class="experience-details">
                    Disney Research, Zürich, Research Intern
                    <br>Advisor: Dr. Yang Zhang
                </div>
            </div>

            <div class="experience-item">
                <div class="experience-logo">
                    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Microsoft_logo_%282012%29.svg/512px-Microsoft_logo_%282012%29.svg.png" alt="Microsoft Logo">
                </div>
                <div class="experience-details">
                    Microsoft Research Asia, AI Residency
                    <br>Mentors: Dr. Zhirong Wu, Dr. Steve Lin
                </div>
            </div>

            <div class="experience-item">
                <div class="experience-logo">
                    <img src="images/ucb_logo.png" alt="UC Berkeley Logo">
                </div>
                <div class="experience-details">
                    <strong>University of California, Berkeley</strong>, Visiting Student
                    <br>Advisor: Prof. Stella Yu
                </div>
            </div>

            <div class="experience-item">
                <div class="experience-logo">
                    <img src="images/jhulogo.png" alt="JHU Logo">
                </div>
                <div class="experience-details">
                    <strong>Johns Hopkins University</strong>, Visiting Student
                    <br>Advisor: Prof. Alan Yuille
                </div>
            </div>
        </div>
    </div>

    <div class="section">
        <h2>Selected Research</h2>
        
        <h3 style="color: blue; font-weight: bold;">GenAI RL/Reasoning/Agent</h3>
        
        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">LongVideoAgent: Multi-Agent Reasoning with Long Videos</div>
                <div class="publication-authors"><strong>R Liu</strong>, Z Liu, J Tang, Y Ma, R Pi, J Zhang, Q Chen</div>
                <div class="publication-venue">arXiv 2025, under review</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">Fake it till You Make it: Reward Modeling as Discriminative Prediction</div>
                <div class="publication-authors"><strong>R Liu</strong>, J Zhan, Y He, C Wei, Alan Yuille, Qifeng Chen</div>
                <div class="publication-venue">arXiv 2025, under review</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">VideoDPO: Omni-Preference Alignment for Video Diffusion Generation</div>
                <div class="publication-authors"><strong>R Liu</strong>, H Wu, Z Ziqiang, C Wei, Y He, R Pi, Qifeng Chen</div>
                <div class="publication-venue">CVPR 2025</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">AlignGuard: Scalable Safety Alignment for Text-to-Image Generation</div>
                <div class="publication-authors"><strong>R Liu</strong>, IC Chen, J Gu, J Zhang, R Pi, Q Chen, Philip Torr, Ashkan Khakzar, Fabio Pizzati</div>
                <div class="publication-venue">ICCV 2025</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">Utmath: Math evaluation with unit test via reasoning-to-coding thoughts</div>
                <div class="publication-authors">B Yang, Q Yang, Y Ma, <strong>R Liu</strong></div>
                <div class="publication-venue">EMNLP 2025 Findings</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">I Think, Therefore I Diffuse: Enabling Multimodal In-Context Reasoning in Diffusion Models</div>
                <div class="publication-authors">Z Mi, KC Wang, G Qian, H Ye, <strong>R Liu</strong>, S Tulyakov, K Aberman, Dan Xu</div>
                <div class="publication-venue">ICML 2025 (Poster)</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization</div>
                <div class="publication-authors">R Pi, T Han, W Xiong, J Zhang, <strong>R Liu</strong>, R Pan, Tong Zhang</div>
                <div class="publication-venue">ECCV 2024 (<span style="color:red">Oral</span>)</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models</div>
                <div class="publication-authors">R Pi, K Miao, P Li, <strong>R Liu</strong>, J Gao, J Zhang, X Zhou</div>
                <div class="publication-venue">EMNLP 2025 Main</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">VL-GenRM: Enhancing Vision-Language Verification via Vision Experts and Iterative Training</div>
                <div class="publication-authors">J Zhang, K Miao, R Pi, Z Wang, <strong>R Liu</strong>, R Pan, Tong Zhang</div>
                <div class="publication-venue">arXiv 2025, under review</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">LLMs Meet Multimodal Generation and Editing: A Survey</div>
                <div class="publication-authors">Y. He, Z. Liu, J. Chen, Z. Tian, H. Liu, X. Chi, <strong>R Liu</strong>, ..., Qifeng Chen</div>
                <div class="publication-venue">arXiv 2024, in progress</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <h3 style="color: blue; font-weight: bold;">Visual Generation and Understanding</h3>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">Latent Guard: a Safety Framework for Text-to-image Generation</div>
                <div class="publication-authors"><strong>R Liu</strong>, A Khakzar, J Gu, Q Chen, Philip Torr, Fabio Pizzati</div>
                <div class="publication-venue">ECCV 2024 (Poster)</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">Unsupervised Sketch-to-Photo Synthesis</div>
                <div class="publication-authors"><strong>R Liu</strong>, Q Yu, Stella Yu</div>
                <div class="publication-venue">ECCV 2020 (<span style="color:red">Oral</span>)</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">The Emergence of Objectness: Learning Zero-Shot Segmentation from Videos</div>
                <div class="publication-authors"><strong>R Liu</strong>, Z Wu, Stella Yu, Steve Lin</div>
                <div class="publication-venue">NeurIPS 2021</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">CLEVR-Ref+: Diagnosing Visual Reasoning with Referring Expressions</div>
                <div class="publication-authors"><strong>R Liu</strong>, C Liu, Y Bai, Alan Yuille</div>
                <div class="publication-venue">CVPR 2019</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">Automatic Document Metadata Extraction Based on Deep Networks</div>
                <div class="publication-authors"><strong>R Liu</strong>, L Gao, D An, Z Jiang, Z Tang</div>
                <div class="publication-venue">NLPCC 2017 (<span style="color:red">Oral</span>)</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">ModelGrow: Continual Text-to-Video Pre-training with Model Expansion and Language Understanding Enhancement</div>
                <div class="publication-authors">Z Rao, L Ji, Y Xing, <strong>R Liu</strong>, Z Liu, J Xie, Z Peng, Y He, Qifeng Chen</div>
                <div class="publication-venue">arXiv 2024, under review</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">SketchInverter: Multi-Class Sketch-Based Image Generation via GAN Inversion</div>
                <div class="publication-authors">J Yu, Z An, <strong>R Liu</strong>, C Wang, Qian Yu</div>
                <div class="publication-venue">WACV 2023 (Poster)</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

        <div class="publication-item">
            <div class="publication-content">
                <div class="publication-title">3D Shape Reconstruction from Free-Hand Sketches</div>
                <div class="publication-authors">J Wang, J Lin, Q Yu, <strong>R Liu</strong>, Y Chen, Stella Yu</div>
                <div class="publication-venue">ECCV Workshop 2022</div>
                <div class="publication-links">
                </div>
            </div>
        </div>

    </div>

    <div class="section">
        <h2>Selected Awards</h2>
        <div class="section-content">
            <ul>
                <li>HKUST RedBird Academic Excellence Award, 2024, 2025</li>
                <li>Silver Medal in 41th ACM/ICPC Asia Regional Qingdao Onsite, 2016</li>
                <li>Silver Medal in 41th ACM/ICPC Asia Regional Shenyang Onsite, 2016</li>
                <li>Silver Medal in China Collegiate Programming Contest (Xiangtan Invitational Onsite), 2016</li>
                <!-- <li>Peking University Freshmen Outstanding Scholarship (1st/24), 2017</li>
                <li>Beijing Outstanding Graduate, 2017</li> -->
            </ul>
        </div>
    </div>

    <div class="footer">
        <p>
            Source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
            <br>
            &copy; 2025 Runtao Liu.
        </p>
    </div>

<div style="width: 33%; margin: 0 auto;">
    <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=FvMkA1dO4OUJwV6u1ftuK1EDLd8V9zH1UHaqlQ1wZHI&cl=ffffff&w=a"></script>
</div>
</body>
</html>
